{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nauthor @ nicole diaz flores\\ndate: 02/01/2021\\nclass: Data Modeling BSSD3850\\nProf @ Jonathan Lee\\n'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "author @ nicole diaz flores\n",
    "date: 02/01/2021\n",
    "class: Data Modeling BSSD3850\n",
    "Prof @ Jonathan Lee\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------- IMPORTS\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(iterations):\n",
    "    step = 0.1\n",
    "    for itr in range(iterations):\n",
    "        print(itr,weights)\n",
    "        \n",
    "        num_errors=0\n",
    "        \n",
    "        for i in range(len(input_data)):\n",
    "            #pull out weights after the 0 position\n",
    "            w_sum = weighted_sum(input_data[i],weights[1:])\n",
    "            #add bias (first weight)\n",
    "            w_sum = weights[0]+w+sum\n",
    "            \n",
    "            act = activation(w_sum,threshold)\n",
    "            print(act,output_labels[i])\n",
    "            \n",
    "            error = output_labels[i]-act\n",
    "           \n",
    "            if error != 0: \n",
    "                num_errors+=1        \n",
    "                #updating weights\n",
    "                weights[0] += step * error * input_data[i][0]\n",
    "                weights[1] += step * error * input_data[i][1]\n",
    "                \n",
    "            if num_errors == 0:\n",
    "                print(itr,weights)\n",
    "                break\n",
    "            else:\n",
    "                print(\"no answer\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------- WEIGHT TESTING\n",
    "def test_weights(w,act):\n",
    "    for i in range(len(input_data)):\n",
    "        vs = weighted_sum(input_data[i],w[1:]+weights[0])\n",
    "        print(act(vs,threshold),output_labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------- WEIGHTED SUM\n",
    "def weighted_sum(vec,weights):\n",
    "    w_vector = vec*weights\n",
    "    return w_vector.sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------- ACTIVATION\n",
    "def activation(val,threshold):\n",
    "    if val >= threshold:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.01423825 -0.4911238 ]\n",
      "0 [ 0.08576175 -0.3911238 ]\n",
      "0 1\n",
      "no answer\n",
      "0 0\n",
      "0 [ 0.26451693 -0.28046541]\n",
      "1 [ 0.36451693 -0.18046541]\n",
      "0 1\n",
      "no answer\n",
      "0 0\n",
      "1 [ 0.54327211 -0.06980702]\n",
      "2 [0.64327211 0.03019298]\n",
      "0 1\n",
      "no answer\n",
      "0 0\n",
      "2 [0.8220273  0.14085137]\n",
      "3 [0.9220273  0.24085137]\n",
      "0 1\n",
      "no answer\n",
      "0 0\n",
      "3 [1.10078248 0.35150976]\n",
      "4 [1.20078248 0.45150976]\n",
      "1 1\n",
      "4 [1.20078248 0.45150976]\n",
      "5 [1.30078248 0.55150976]\n",
      "1 1\n",
      "5 [1.30078248 0.55150976]\n",
      "6 [1.40078248 0.65150976]\n",
      "1 1\n",
      "6 [1.40078248 0.65150976]\n",
      "7 [1.50078248 0.75150976]\n",
      "1 1\n",
      "7 [1.50078248 0.75150976]\n",
      "8 [1.60078248 0.85150976]\n",
      "1 1\n",
      "8 [1.60078248 0.85150976]\n",
      "9 [1.70078248 0.95150976]\n",
      "1 1\n",
      "9 [1.70078248 0.95150976]\n",
      "10 [1.80078248 1.05150976]\n",
      "1 1\n",
      "10 [1.80078248 1.05150976]\n",
      "11 [1.90078248 1.15150976]\n",
      "1 1\n",
      "11 [1.90078248 1.15150976]\n",
      "12 [2.00078248 1.25150976]\n",
      "1 1\n",
      "12 [2.00078248 1.25150976]\n",
      "13 [2.10078248 1.35150976]\n",
      "1 1\n",
      "13 [2.10078248 1.35150976]\n",
      "14 [2.20078248 1.45150976]\n",
      "1 1\n",
      "14 [2.20078248 1.45150976]\n",
      "15 [2.30078248 1.55150976]\n",
      "1 1\n",
      "15 [2.30078248 1.55150976]\n",
      "16 [2.40078248 1.65150976]\n",
      "1 1\n",
      "16 [2.40078248 1.65150976]\n",
      "17 [2.50078248 1.75150976]\n",
      "1 1\n",
      "17 [2.50078248 1.75150976]\n",
      "18 [2.60078248 1.85150976]\n",
      "1 1\n",
      "18 [2.60078248 1.85150976]\n",
      "19 [2.70078248 1.95150976]\n",
      "1 1\n",
      "19 [2.70078248 1.95150976]\n",
      "20 [2.80078248 2.05150976]\n",
      "1 1\n",
      "20 [2.80078248 2.05150976]\n",
      "21 [2.90078248 2.15150976]\n",
      "1 1\n",
      "21 [2.90078248 2.15150976]\n",
      "22 [3.00078248 2.25150976]\n",
      "1 1\n",
      "22 [3.00078248 2.25150976]\n",
      "23 [3.10078248 2.35150976]\n",
      "1 1\n",
      "23 [3.10078248 2.35150976]\n",
      "24 [3.20078248 2.45150976]\n",
      "1 1\n",
      "24 [3.20078248 2.45150976]\n",
      "25 [3.30078248 2.55150976]\n",
      "1 1\n",
      "25 [3.30078248 2.55150976]\n",
      "26 [3.40078248 2.65150976]\n",
      "1 1\n",
      "26 [3.40078248 2.65150976]\n",
      "27 [3.50078248 2.75150976]\n",
      "1 1\n",
      "27 [3.50078248 2.75150976]\n",
      "28 [3.60078248 2.85150976]\n",
      "1 1\n",
      "28 [3.60078248 2.85150976]\n",
      "29 [3.70078248 2.95150976]\n",
      "1 1\n",
      "29 [3.70078248 2.95150976]\n",
      "30 [3.80078248 3.05150976]\n",
      "1 1\n",
      "30 [3.80078248 3.05150976]\n",
      "31 [3.90078248 3.15150976]\n",
      "1 1\n",
      "31 [3.90078248 3.15150976]\n",
      "32 [4.00078248 3.25150976]\n",
      "1 1\n",
      "32 [4.00078248 3.25150976]\n",
      "33 [4.10078248 3.35150976]\n",
      "1 1\n",
      "33 [4.10078248 3.35150976]\n",
      "34 [4.20078248 3.45150976]\n",
      "1 1\n",
      "34 [4.20078248 3.45150976]\n",
      "35 [4.30078248 3.55150976]\n",
      "1 1\n",
      "35 [4.30078248 3.55150976]\n",
      "36 [4.40078248 3.65150976]\n",
      "1 1\n",
      "36 [4.40078248 3.65150976]\n",
      "37 [4.50078248 3.75150976]\n",
      "1 1\n",
      "37 [4.50078248 3.75150976]\n",
      "38 [4.60078248 3.85150976]\n",
      "1 1\n",
      "38 [4.60078248 3.85150976]\n",
      "39 [4.70078248 3.95150976]\n",
      "1 1\n",
      "39 [4.70078248 3.95150976]\n",
      "40 [4.80078248 4.05150976]\n",
      "1 1\n",
      "40 [4.80078248 4.05150976]\n",
      "41 [4.90078248 4.15150976]\n",
      "1 1\n",
      "41 [4.90078248 4.15150976]\n",
      "42 [5.00078248 4.25150976]\n",
      "1 1\n",
      "42 [5.00078248 4.25150976]\n",
      "43 [5.10078248 4.35150976]\n",
      "1 1\n",
      "43 [5.10078248 4.35150976]\n",
      "44 [5.20078248 4.45150976]\n",
      "1 1\n",
      "44 [5.20078248 4.45150976]\n",
      "45 [5.30078248 4.55150976]\n",
      "1 1\n",
      "45 [5.30078248 4.55150976]\n",
      "46 [5.40078248 4.65150976]\n",
      "1 1\n",
      "46 [5.40078248 4.65150976]\n",
      "47 [5.50078248 4.75150976]\n",
      "1 1\n",
      "47 [5.50078248 4.75150976]\n",
      "48 [5.60078248 4.85150976]\n",
      "1 1\n",
      "48 [5.60078248 4.85150976]\n",
      "49 [5.70078248 4.95150976]\n",
      "1 1\n",
      "49 [5.70078248 4.95150976]\n",
      "50 [5.80078248 5.05150976]\n",
      "1 1\n",
      "50 [5.80078248 5.05150976]\n",
      "51 [5.90078248 5.15150976]\n",
      "1 1\n",
      "51 [5.90078248 5.15150976]\n",
      "52 [6.00078248 5.25150976]\n",
      "1 1\n",
      "52 [6.00078248 5.25150976]\n",
      "53 [6.10078248 5.35150976]\n",
      "1 1\n",
      "53 [6.10078248 5.35150976]\n",
      "54 [6.20078248 5.45150976]\n",
      "1 1\n",
      "54 [6.20078248 5.45150976]\n",
      "55 [6.30078248 5.55150976]\n",
      "1 1\n",
      "55 [6.30078248 5.55150976]\n",
      "56 [6.40078248 5.65150976]\n",
      "1 1\n",
      "56 [6.40078248 5.65150976]\n",
      "57 [6.50078248 5.75150976]\n",
      "1 1\n",
      "57 [6.50078248 5.75150976]\n",
      "58 [6.60078248 5.85150976]\n",
      "1 1\n",
      "58 [6.60078248 5.85150976]\n",
      "59 [6.70078248 5.95150976]\n",
      "1 1\n",
      "59 [6.70078248 5.95150976]\n",
      "60 [6.80078248 6.05150976]\n",
      "1 1\n",
      "60 [6.80078248 6.05150976]\n",
      "61 [6.90078248 6.15150976]\n",
      "1 1\n",
      "61 [6.90078248 6.15150976]\n",
      "62 [7.00078248 6.25150976]\n",
      "1 1\n",
      "62 [7.00078248 6.25150976]\n",
      "63 [7.10078248 6.35150976]\n",
      "1 1\n",
      "63 [7.10078248 6.35150976]\n",
      "64 [7.20078248 6.45150976]\n",
      "1 1\n",
      "64 [7.20078248 6.45150976]\n",
      "65 [7.30078248 6.55150976]\n",
      "1 1\n",
      "65 [7.30078248 6.55150976]\n",
      "66 [7.40078248 6.65150976]\n",
      "1 1\n",
      "66 [7.40078248 6.65150976]\n",
      "67 [7.50078248 6.75150976]\n",
      "1 1\n",
      "67 [7.50078248 6.75150976]\n",
      "68 [7.60078248 6.85150976]\n",
      "1 1\n",
      "68 [7.60078248 6.85150976]\n",
      "69 [7.70078248 6.95150976]\n",
      "1 1\n",
      "69 [7.70078248 6.95150976]\n",
      "70 [7.80078248 7.05150976]\n",
      "1 1\n",
      "70 [7.80078248 7.05150976]\n",
      "71 [7.90078248 7.15150976]\n",
      "1 1\n",
      "71 [7.90078248 7.15150976]\n",
      "72 [8.00078248 7.25150976]\n",
      "1 1\n",
      "72 [8.00078248 7.25150976]\n",
      "73 [8.10078248 7.35150976]\n",
      "1 1\n",
      "73 [8.10078248 7.35150976]\n",
      "74 [8.20078248 7.45150976]\n",
      "1 1\n",
      "74 [8.20078248 7.45150976]\n",
      "75 [8.30078248 7.55150976]\n",
      "1 1\n",
      "75 [8.30078248 7.55150976]\n",
      "76 [8.40078248 7.65150976]\n",
      "1 1\n",
      "76 [8.40078248 7.65150976]\n",
      "77 [8.50078248 7.75150976]\n",
      "1 1\n",
      "77 [8.50078248 7.75150976]\n",
      "78 [8.60078248 7.85150976]\n",
      "1 1\n",
      "78 [8.60078248 7.85150976]\n",
      "79 [8.70078248 7.95150976]\n",
      "1 1\n",
      "79 [8.70078248 7.95150976]\n",
      "80 [8.80078248 8.05150976]\n",
      "1 1\n",
      "80 [8.80078248 8.05150976]\n",
      "81 [8.90078248 8.15150976]\n",
      "1 1\n",
      "81 [8.90078248 8.15150976]\n",
      "82 [9.00078248 8.25150976]\n",
      "1 1\n",
      "82 [9.00078248 8.25150976]\n",
      "83 [9.10078248 8.35150976]\n",
      "1 1\n",
      "83 [9.10078248 8.35150976]\n",
      "84 [9.20078248 8.45150976]\n",
      "1 1\n",
      "84 [9.20078248 8.45150976]\n",
      "85 [9.30078248 8.55150976]\n",
      "1 1\n",
      "85 [9.30078248 8.55150976]\n",
      "86 [9.40078248 8.65150976]\n",
      "1 1\n",
      "86 [9.40078248 8.65150976]\n",
      "87 [9.50078248 8.75150976]\n",
      "1 1\n",
      "87 [9.50078248 8.75150976]\n",
      "88 [9.60078248 8.85150976]\n",
      "1 1\n",
      "88 [9.60078248 8.85150976]\n",
      "89 [9.70078248 8.95150976]\n",
      "1 1\n",
      "89 [9.70078248 8.95150976]\n",
      "90 [9.80078248 9.05150976]\n",
      "1 1\n",
      "90 [9.80078248 9.05150976]\n",
      "91 [9.90078248 9.15150976]\n",
      "1 1\n",
      "91 [9.90078248 9.15150976]\n",
      "92 [10.00078248  9.25150976]\n",
      "1 1\n",
      "92 [10.00078248  9.25150976]\n",
      "93 [10.10078248  9.35150976]\n",
      "1 1\n",
      "93 [10.10078248  9.35150976]\n",
      "94 [10.20078248  9.45150976]\n",
      "1 1\n",
      "94 [10.20078248  9.45150976]\n",
      "95 [10.30078248  9.55150976]\n",
      "1 1\n",
      "95 [10.30078248  9.55150976]\n",
      "96 [10.40078248  9.65150976]\n",
      "1 1\n",
      "96 [10.40078248  9.65150976]\n",
      "97 [10.50078248  9.75150976]\n",
      "1 1\n",
      "97 [10.50078248  9.75150976]\n",
      "98 [10.60078248  9.85150976]\n",
      "1 1\n",
      "98 [10.60078248  9.85150976]\n",
      "99 [10.70078248  9.95150976]\n",
      "1 1\n",
      "99 [10.70078248  9.95150976]\n",
      "1 1\n",
      "1 0\n",
      "1 0\n",
      "1 1\n",
      "1 0\n",
      "1 0\n",
      "1 1\n",
      "0 0\n",
      "1 0\n",
      "1 1\n",
      "1 0\n",
      "1 0\n",
      "1 1\n",
      "1 0\n",
      "1 0\n",
      "1 1\n",
      "1 0\n",
      "1 0\n",
      "1 1\n",
      "1 0\n",
      "1 0\n",
      "1 1\n",
      "0 0\n",
      "1 0\n",
      "1 1\n",
      "1 0\n",
      "1 0\n",
      "1 1\n",
      "1 0\n",
      "1 0\n",
      "1 1\n",
      "1 0\n",
      "1 0\n",
      "1 1\n",
      "1 0\n",
      "1 0\n",
      "1 1\n",
      "1 0\n",
      "1 0\n",
      "1 1\n",
      "1 0\n",
      "1 0\n",
      "1 1\n",
      "1 0\n",
      "1 0\n",
      "1 1\n",
      "1 0\n",
      "1 0\n",
      "1 1\n",
      "1 0\n",
      "1 0\n",
      "1 1\n",
      "1 0\n",
      "1 0\n",
      "1 1\n",
      "1 0\n",
      "1 0\n",
      "1 1\n",
      "1 0\n",
      "1 0\n",
      "1 1\n",
      "1 0\n",
      "1 0\n",
      "1 1\n",
      "1 0\n",
      "1 0\n",
      "1 1\n",
      "1 0\n",
      "1 0\n",
      "1 1\n",
      "1 0\n",
      "1 0\n",
      "1 1\n",
      "1 0\n",
      "1 0\n",
      "1 1\n",
      "1 0\n",
      "1 0\n",
      "1 1\n",
      "1 0\n",
      "1 0\n",
      "1 1\n",
      "1 0\n",
      "1 0\n",
      "1 1\n",
      "1 0\n",
      "1 0\n",
      "1 1\n",
      "1 0\n",
      "1 0\n"
     ]
    }
   ],
   "source": [
    "######################## MAIN() #########################\n",
    "\n",
    "\n",
    "#---------------------------------------------- DATA\n",
    "#precise data\n",
    "p_labels=[]\n",
    "p_rounds=[]\n",
    "\n",
    "#setting up data (random)\n",
    "for i in range(100):\n",
    "    donut = [np.random.uniform(1.0,2.0),np.random.uniform(1.0,2.0)]\n",
    "    s_bagel = [np.random.uniform(0.0,0.5),np.random.uniform(0.0,0.5)]\n",
    "    r_bagel = [np.random.uniform(0.5,1.0),np.random.uniform(0.5,1.0)]\n",
    "    \n",
    "    p_rounds += [donut,s_bagel,r_bagel]\n",
    "    p_labels += [1,0,0]\n",
    "    \n",
    "#splitting data (training & testing)\n",
    "ratio = int(len(p_rounds)*.7)\n",
    "\n",
    "#trainig sets\n",
    "train_input = np.array(p_rounds[:ratio])\n",
    "train_labels = np.array(p_labels[:ratio])\n",
    "\n",
    "#testing sets\n",
    "test_input = np.array(p_rounds[ratio:])\n",
    "test_labels = np.array(p_labels[ratio:])\n",
    "\n",
    "#input & labels\n",
    "input_data = train_input\n",
    "output_labels = train_labels\n",
    "\n",
    "#------------------------------------------- BIAS\n",
    "bias = np.random.uniform(-1.0,1.0)\n",
    "\n",
    "#------------------------------------------- WEIGHTS\n",
    "weights = np.array([np.random.uniform(-1.0,1.0),np.random.uniform(-1.0,1.0)])\n",
    "print(weights)\n",
    "\n",
    "\n",
    "#------------------------------------------- THRESHOLD\n",
    "threshold = 2.0\n",
    "\n",
    "\n",
    "#------------------------------------------- ITERATIONS\n",
    "iterations = 100\n",
    "fit(iterations)\n",
    "\n",
    "\n",
    "#idk why were doing this but ok...\n",
    "input_data = test_input\n",
    "output_labels = test_labels\n",
    "#---------------------------------------- WEIGHT TESTING\n",
    "test_weights(weights,activation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
